{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "67da5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segpy.reader import create_reader\n",
    "import numpy as np\n",
    "import os\n",
    "import pywt\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0cda7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "directory = r'C:\\Users\\user\\Desktop\\2D\\Correlated_Shot_Gathers'\n",
    "\n",
    "for file_name in os.listdir(directory):\n",
    "    \n",
    "    if file_name != \".segpy\":\n",
    "        \n",
    "        with open(directory + \"\\\\\" + file_name, 'rb') as segy_in_file:\n",
    "\n",
    "            seg_y_dataset = create_reader(segy_in_file, endian='<')\n",
    "\n",
    "            for i in seg_y_dataset.trace_indexes():\n",
    "                dataset.append(seg_y_dataset.trace_samples(i))\n",
    "            \n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "def4bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dataset = np.max(dataset, axis = 1)\n",
    "min_dataset = np.min(dataset, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8001e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (dataset - np.repeat(np.expand_dims(min_dataset,axis = 1), 4001, axis = 1))/(np.repeat(np.expand_dims(max_dataset,axis = 1), 4001, axis = 1) - np.repeat(np.expand_dims(min_dataset,axis = 1), 4001, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0c091552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dct(dataset, block_size = 32):\n",
    "    \n",
    "    dataset = dataset[:,:len(dataset[0]) - len(dataset[0])%block_size]\n",
    "    dataset = dataset.reshape((len(dataset), len(dataset[0])//block_size, block_size))\n",
    "    dataset = dct(dataset, norm = 'ortho', axis = 2)\n",
    "    \n",
    "    return dataset.reshape((len(dataset), dataset.shape[1]*dataset.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc1ce724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def quantize(signal, levels):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = levels).fit(signal.reshape(-1,1))\n",
    "    \n",
    "    return kmeans.labels_, kmeans.cluster_centers_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3005f63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-178-c1369a467859>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-178-c1369a467859>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def symbol_seqsymbols, levels):\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def symbol_seqsymbols, levels):\n",
    "\n",
    "    return {i:np.mean(symbols == i) for i in np.arange(levels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_huffman_codes(symbol_probabilities):\n",
    "    \n",
    "    huffman_code = {str(key):'' for key in symbol_probabilities.keys()}\n",
    "    symbol_probabilities = {str(key):symbol_probabilities[key] for key in symbol_probabilities.keys()}\n",
    "    \n",
    "    while(len(symbol_probabilities) != 1):\n",
    "        \n",
    "        key1 = min(symbol_probabilities, key=symbol_probabilities.get)\n",
    "        value1 = symbol_probabilities[key1]\n",
    "        symbol_probabilities.pop(key1)\n",
    "        \n",
    "        key2 = min(symbol_probabilities, key=symbol_probabilities.get)\n",
    "        value2 = symbol_probabilities[key2]\n",
    "        symbol_probabilities.pop(key2)\n",
    "        \n",
    "        for symbol in key1.split('|'):\n",
    "            huffman_code[symbol] += '1'\n",
    "            \n",
    "        for symbol in key2.split('|'):\n",
    "            huffman_code[symbol] += '0'\n",
    "            \n",
    "        symbol_probabilities[key1 + '|' + key2] = value1 + value2\n",
    "            \n",
    "    return {int(key):huffman_code[key][::-1] for key in huffman_code.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idct(dataset, block_size = 32):\n",
    "    \n",
    "    dataset = dataset.reshape((len(dataset), len(dataset[0])//block_size, block_size))\n",
    "    dataset = idct(dataset, norm = 'ortho', axis = 2)\n",
    "    \n",
    "    return dataset.reshape((len(dataset), dataset.shape[1]*dataset.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731aa906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x,x_pred):\n",
    "    nmse = np.sum(np.square(x - x_pred))/np.sum(np.square(x))\n",
    "    nrmse = np.sqrt(np.mean(np.square(x - x_pred)))/(np.amax(x) - np.amin(x))\n",
    "    snr = -10*np.log10(nmse)\n",
    "    return nmse, nrmse, snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "21320631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cr_and_metrics(dataset, block_size = 32, level = 8):\n",
    "    \n",
    "    nmse, nrmse, snr = np.zeros(len(dataset)), np.zeros(len(dataset)), np.zeros(len(dataset))\n",
    "    \n",
    "    dct_dataset = compute_dct(dataset, block_size)\n",
    "    \n",
    "    quantized_dct_dataset = np.zeros(np.shape(dct_dataset))\n",
    "    \n",
    "    total_length = 0\n",
    "    \n",
    "    for i, sample in enumerate(dct_dataset):\n",
    "        sym, val = quantize(sample, level)\n",
    "        quantized_dct_dataset[i] = np.array([val[j] for j in sym])\n",
    "        \n",
    "        for key, value in get_huffman_codes(get_probability_dictionary(sym, level)).items():\n",
    "            total_length += np.sum(sym == key)*len(value)\n",
    "        \n",
    "    reconstructed_dataset = compute_idct(quantized_dct_dataset, block_size)\n",
    "    \n",
    "    for j in range(len(dataset)):\n",
    "        nmse[j], nrmse[j], snr[j] = get_metrics(dataset[j,:len(reconstructed_dataset[0])], reconstructed_dataset[j])\n",
    "        \n",
    "    return 4001*64*len(dataset)/total_length, np.mean(nmse), np.mean(nrmse), np.mean(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "46dacd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64.016, 0.02468293508842079, 0.07496052558016722, 17.226486039779356)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aa89f972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.81644673715811,\n",
       " 0.012699658914758423,\n",
       " 0.05353315646203852,\n",
       " 20.21562790362923)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10779a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.31394213429278,\n",
       " 0.0038784370393522734,\n",
       " 0.02963951549634352,\n",
       " 25.379319127371154)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7630ecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.19534044909681,\n",
       " 0.0009332954307914011,\n",
       " 0.014462819529840434,\n",
       " 31.73401582702686)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ab324d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.03333285259415,\n",
       " 0.00018965165385133182,\n",
       " 0.006436731075366694,\n",
       " 38.944619141611795)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4205b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.175943057143193,\n",
       " 3.0992785521815316e-05,\n",
       " 0.0025659117798418683,\n",
       " 47.181498937837894)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4b335f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.3858815287182,\n",
       " 3.686440832473809e-06,\n",
       " 0.0008750103959432993,\n",
       " 56.796527051268484)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b49c9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-082af86be138>:23: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  return 4001*64*len(dataset)/total_length, np.mean(nmse), np.mean(nrmse), np.mean(snr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, 0.9695774326130164, 0.5057045108468173, 0.1341764919036728)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cr_and_metrics(dataset[900:1000], block_size = 32, level = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766e5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
